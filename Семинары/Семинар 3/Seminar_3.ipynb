{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "acc5a9b0",
   "metadata": {},
   "source": [
    "# План семинара\n",
    "- Функционалы и метрики\n",
    "- Кросс-валидация\n",
    "- Переобучение и регуляризация\n",
    "- Гиперпараметры и их оптимизация"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e5ed40",
   "metadata": {},
   "source": [
    "# Функционалы и метрики\n",
    "\n",
    "Quick recap\n",
    "\n",
    "Функционал (или функция потерь == loss function)  - это функция, позволяющая обучить модель (то есть то, что мы стараемся оптимизировать, подбирая параметры модели - в случае линейной регрессии параметры - это веса)\n",
    "\n",
    "Метрика - это оценка качества модели, которую можно использовать к любым моделям (позволяет ответить на вопрос, насколько точно модель может предсказывать целевую переменную)\n",
    "\n",
    "Пример: Чтобы обучить линейную регрессию мы можем минизировать функционал MSE\n",
    "\n",
    "Если мы имеем n наблюдений и k признаков\n",
    "\n",
    "$\\Sigma_{i=0}^{n}(\\hat y_{i} - y_{i})^{2} \\rightarrow min_{w}$\n",
    "\n",
    "где $\\hat y_{i} = \\Sigma_{i=0}^{k}w_{k}X_{ik}$\n",
    "\n",
    "А как метрику можем использовать RMSE\n",
    "\n",
    "$RMSE = \\sqrt{\\Sigma_{i=0}^{n}(\\hat y_{i} - y_{i})^{2}}$\n",
    "\n",
    "Фундаментальное различие функционала и метрик в том, что метрика должна отражать нашу бизнес-задачу или научный вопрос, а функционал должен быть подобран так, чтобы он лучше лучше всего помогал достичь цель (позволял достичь наилучшных показателей метрики или метрик)\n",
    "\n",
    "Аналогия из обучения в вышке: Чтобы сдать матан, мы можем учить производные различных функций, то есть тогда наш функционал - это количество производных, которые мы знаем. А метрикой того, что мы сдали матан будет являться оценка, полученная в конце курса.\n",
    "\n",
    "Оценка в курсе - это понятная метрика, которую нам дал мир. А является ли зубрежка производных лучшим функционалом для достижения поставленной цели решать уже вам, как исследователям\n",
    "\n",
    "И еще, хотя функционал и метрики - это разные по смыслу и использованию инстурменты, они могут быть считаться одинаково (то есть к примеру обучать линейную регрессию можно обучать с помощью функционала MSE, и проверять качество тоже можно с помощью MSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "bf0cd6af",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-20T20:03:51.857595Z",
     "start_time": "2021-09-20T20:03:51.853794Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.datasets import load_diabetes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "479241c9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-20T20:03:51.868197Z",
     "start_time": "2021-09-20T20:03:51.860440Z"
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "d6afdc27",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-20T20:03:51.891504Z",
     "start_time": "2021-09-20T20:03:51.889057Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "818d9dff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-20T20:03:51.921761Z",
     "start_time": "2021-09-20T20:03:51.893244Z"
    }
   },
   "outputs": [],
   "source": [
    "X, y = load_diabetes(return_X_y=True,as_frame=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "705ca49c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-20T20:03:51.942848Z",
     "start_time": "2021-09-20T20:03:51.923438Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>bp</th>\n",
       "      <th>s1</th>\n",
       "      <th>s2</th>\n",
       "      <th>s3</th>\n",
       "      <th>s4</th>\n",
       "      <th>s5</th>\n",
       "      <th>s6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.038076</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.061696</td>\n",
       "      <td>0.021872</td>\n",
       "      <td>-0.044223</td>\n",
       "      <td>-0.034821</td>\n",
       "      <td>-0.043401</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>0.019908</td>\n",
       "      <td>-0.017646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.001882</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.051474</td>\n",
       "      <td>-0.026328</td>\n",
       "      <td>-0.008449</td>\n",
       "      <td>-0.019163</td>\n",
       "      <td>0.074412</td>\n",
       "      <td>-0.039493</td>\n",
       "      <td>-0.068330</td>\n",
       "      <td>-0.092204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.085299</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.044451</td>\n",
       "      <td>-0.005671</td>\n",
       "      <td>-0.045599</td>\n",
       "      <td>-0.034194</td>\n",
       "      <td>-0.032356</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>0.002864</td>\n",
       "      <td>-0.025930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.089063</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.011595</td>\n",
       "      <td>-0.036656</td>\n",
       "      <td>0.012191</td>\n",
       "      <td>0.024991</td>\n",
       "      <td>-0.036038</td>\n",
       "      <td>0.034309</td>\n",
       "      <td>0.022692</td>\n",
       "      <td>-0.009362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.005383</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.036385</td>\n",
       "      <td>0.021872</td>\n",
       "      <td>0.003935</td>\n",
       "      <td>0.015596</td>\n",
       "      <td>0.008142</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>-0.031991</td>\n",
       "      <td>-0.046641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>0.041708</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.019662</td>\n",
       "      <td>0.059744</td>\n",
       "      <td>-0.005697</td>\n",
       "      <td>-0.002566</td>\n",
       "      <td>-0.028674</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>0.031193</td>\n",
       "      <td>0.007207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>-0.005515</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>-0.015906</td>\n",
       "      <td>-0.067642</td>\n",
       "      <td>0.049341</td>\n",
       "      <td>0.079165</td>\n",
       "      <td>-0.028674</td>\n",
       "      <td>0.034309</td>\n",
       "      <td>-0.018118</td>\n",
       "      <td>0.044485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>0.041708</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>-0.015906</td>\n",
       "      <td>0.017282</td>\n",
       "      <td>-0.037344</td>\n",
       "      <td>-0.013840</td>\n",
       "      <td>-0.024993</td>\n",
       "      <td>-0.011080</td>\n",
       "      <td>-0.046879</td>\n",
       "      <td>0.015491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>-0.045472</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>0.039062</td>\n",
       "      <td>0.001215</td>\n",
       "      <td>0.016318</td>\n",
       "      <td>0.015283</td>\n",
       "      <td>-0.028674</td>\n",
       "      <td>0.026560</td>\n",
       "      <td>0.044528</td>\n",
       "      <td>-0.025930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>-0.045472</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.073030</td>\n",
       "      <td>-0.081414</td>\n",
       "      <td>0.083740</td>\n",
       "      <td>0.027809</td>\n",
       "      <td>0.173816</td>\n",
       "      <td>-0.039493</td>\n",
       "      <td>-0.004220</td>\n",
       "      <td>0.003064</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>442 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          age       sex       bmi        bp        s1        s2        s3  \\\n",
       "0    0.038076  0.050680  0.061696  0.021872 -0.044223 -0.034821 -0.043401   \n",
       "1   -0.001882 -0.044642 -0.051474 -0.026328 -0.008449 -0.019163  0.074412   \n",
       "2    0.085299  0.050680  0.044451 -0.005671 -0.045599 -0.034194 -0.032356   \n",
       "3   -0.089063 -0.044642 -0.011595 -0.036656  0.012191  0.024991 -0.036038   \n",
       "4    0.005383 -0.044642 -0.036385  0.021872  0.003935  0.015596  0.008142   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "437  0.041708  0.050680  0.019662  0.059744 -0.005697 -0.002566 -0.028674   \n",
       "438 -0.005515  0.050680 -0.015906 -0.067642  0.049341  0.079165 -0.028674   \n",
       "439  0.041708  0.050680 -0.015906  0.017282 -0.037344 -0.013840 -0.024993   \n",
       "440 -0.045472 -0.044642  0.039062  0.001215  0.016318  0.015283 -0.028674   \n",
       "441 -0.045472 -0.044642 -0.073030 -0.081414  0.083740  0.027809  0.173816   \n",
       "\n",
       "           s4        s5        s6  \n",
       "0   -0.002592  0.019908 -0.017646  \n",
       "1   -0.039493 -0.068330 -0.092204  \n",
       "2   -0.002592  0.002864 -0.025930  \n",
       "3    0.034309  0.022692 -0.009362  \n",
       "4   -0.002592 -0.031991 -0.046641  \n",
       "..        ...       ...       ...  \n",
       "437 -0.002592  0.031193  0.007207  \n",
       "438  0.034309 -0.018118  0.044485  \n",
       "439 -0.011080 -0.046879  0.015491  \n",
       "440  0.026560  0.044528 -0.025930  \n",
       "441 -0.039493 -0.004220  0.003064  \n",
       "\n",
       "[442 rows x 10 columns]"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "9e6e3ca3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-20T20:03:51.955438Z",
     "start_time": "2021-09-20T20:03:51.947473Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      151.0\n",
       "1       75.0\n",
       "2      141.0\n",
       "3      206.0\n",
       "4      135.0\n",
       "       ...  \n",
       "437    178.0\n",
       "438    104.0\n",
       "439    132.0\n",
       "440    220.0\n",
       "441     57.0\n",
       "Name: target, Length: 442, dtype: float64"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "093f5695",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-20T20:03:51.962949Z",
     "start_time": "2021-09-20T20:03:51.957145Z"
    }
   },
   "outputs": [],
   "source": [
    "# Разобьем данные на обучающую и тестовую выборки\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "912f1b35",
   "metadata": {},
   "source": [
    "Как было рассказано на лекции, линейную регрессию можно обучать с помощью разного функционала (не только MSE, который мы разбирали на прошлом семинаре) и оценивать с помощью разных метрик - закодим это "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "b266dd96",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-20T20:03:52.207120Z",
     "start_time": "2021-09-20T20:03:51.964240Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE loss: \n",
      "mae=41.6033954975325\n",
      "mse=2807.5847465489564\n",
      "R2=0.492270841736523\n",
      "\n",
      "MAE loss: \n",
      "mae=62.88154239898715\n",
      "mse=5566.614155205576\n",
      "R2=-0.006677473538126089\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "lr_mse = SGDRegressor(loss='squared_loss', max_iter=50000)\n",
    "lr_mae = SGDRegressor(loss='epsilon_insensitive', epsilon=0, max_iter=50000)\n",
    "\n",
    "lr_mse.fit(X_train, y_train)\n",
    "lr_mae.fit(X_train, y_train)\n",
    "\n",
    "y_pred_mse = lr_mse.predict(X_test)\n",
    "y_pred_mae = lr_mae.predict(X_test)\n",
    "\n",
    "print(f'''MSE loss: \n",
    "mae={mean_absolute_error(y_test, y_pred_mse)}\n",
    "mse={mean_squared_error(y_test, y_pred_mse)}\n",
    "R2={r2_score(y_test, y_pred_mse)}\n",
    "''')\n",
    "\n",
    "print(f'''MAE loss: \n",
    "mae={mean_absolute_error(y_test, y_pred_mae)}\n",
    "mse={mean_squared_error(y_test, y_pred_mae)}\n",
    "R2={r2_score(y_test, y_pred_mae)}\n",
    "''')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19825a90",
   "metadata": {},
   "source": [
    "Как мы говорили раньше, метрика должна отражать реальную цель из мира, поэтому нередко возникает потребность в написании своих собственных метрик, которые лучше описывают вашу конретную реальность. В задачах, связанных с медициной (как у нас сейчас), довольно высокая цена ошибки (у человека есть диабет, а мы его не нашли). Поэтому для того, чтобы ответить на вопрос, можно ли модель использовать в жизни, имеет смысл использовать метрику максимальной ошибки модели\n",
    "\n",
    "$max error = max(|\\hat y_{i} - y_{i}|)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "0af21500",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-20T20:03:52.213290Z",
     "start_time": "2021-09-20T20:03:52.208515Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE Loss: 139.3939392266401\n",
      "MAE Loss: 175.53083687547775\n"
     ]
    }
   ],
   "source": [
    "def max_error(y_true, y_pred):\n",
    "    max_erorr = np.abs(y_true - y_pred).max()\n",
    "    return max_erorr\n",
    "\n",
    "def quantile_error(y_true, y_pred, q=0.95):\n",
    "    q_error = np.quantile(np.abs(y_true -  y_pred), q)\n",
    "    return q_error\n",
    "\n",
    "# Оценим максимальную ошибку в обоих случаях\n",
    "\n",
    "print(f'MSE Loss: {max_error(y_test, y_pred_mse)}')\n",
    "print(f'MAE Loss: {max_error(y_test, y_pred_mae)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afbc9291",
   "metadata": {},
   "source": [
    "BTW, в sklearn есть большое количество уже реализованных метрик - можете посмотреть их список и варианты применения здесь\n",
    "\n",
    "https://scikit-learn.org/stable/modules/model_evaluation.html#regression-metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eecb1ad2",
   "metadata": {},
   "source": [
    "#  Кросс-валидация"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9107f201",
   "metadata": {},
   "source": [
    "Когда выбран функционал и метрика, можно задаться вопросом: а насколько я могу доверять полученным результатам (значениям метрики), не являются ли они случайности или совпадением ? Кросс-валидация - это инструмент для ответа на этот вопрос."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "316b94f3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-20T20:03:52.216719Z",
     "start_time": "2021-09-20T20:03:52.214661Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "244c3991",
   "metadata": {},
   "source": [
    "здесь можно посмотреть какие параметры требуются для этой функции\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_validate.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "05b21625",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-20T20:03:53.112215Z",
     "start_time": "2021-09-20T20:03:52.218043Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test mse errors are [-2991.42348475 -3042.33637016 -3161.79356217 -2902.67746643\n",
      " -3025.94078344]\n",
      "mean test mse = -3024.834333389533\n"
     ]
    }
   ],
   "source": [
    "# проверим на кросс-валидации значения ошибок MSE, MAE, R2 \n",
    "# для линейной регрессии, обученной с помощью функционала MSE\n",
    "\n",
    "num_splits=5\n",
    "\n",
    "cv_res = cross_validate(lr_mse,\n",
    "                     X,\n",
    "                     y,\n",
    "                     scoring='neg_mean_squared_error', # метрика, которую нужно оценить\n",
    "                     cv=num_splits # количество разбиений или класс-сплиттер\n",
    "                    )\n",
    "\n",
    "print(f\"test mse errors are {cv_res['test_score']}\")\n",
    "print(f\"mean test mse = {cv_res['test_score'].mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "ab5906ac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-20T20:03:54.005611Z",
     "start_time": "2021-09-20T20:03:53.114755Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test mse errors are [-2964.5344668  -3036.26795455 -3162.38560005 -2897.2111925\n",
      " -3026.25961788] \n",
      "and  mean mse = -3017.331766354572\n",
      "\n",
      "test mae errors are [-44.8616921  -44.95832561 -48.04493857 -42.72409909 -43.80552224] \n",
      "and  mean mae = -44.87891552110657\n",
      "\n",
      "test R2 are [0.39167374 0.52142803 0.49471233 0.44775769 0.53231415] \n",
      "and  mean R2 = 0.4775771875916902\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Проведем кросс-валидацию сразу для нескольких метрик\n",
    "\n",
    "cv_res2 = cross_validate(lr_mse,\n",
    "                     X,\n",
    "                     y,\n",
    "                     scoring=['neg_mean_squared_error', 'neg_mean_absolute_error', 'r2'],\n",
    "                     cv=num_splits\n",
    "                    )\n",
    "print(f\"\"\"test mse errors are {cv_res2['test_neg_mean_squared_error']} \n",
    "and  mean mse = {cv_res2['test_neg_mean_squared_error'].mean()}\n",
    "\"\"\")\n",
    "\n",
    "print(f\"\"\"test mae errors are {cv_res2['test_neg_mean_absolute_error']} \n",
    "and  mean mae = {cv_res2['test_neg_mean_absolute_error'].mean()}\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "print(f\"\"\"test R2 are {cv_res2['test_r2']} \n",
    "and  mean R2 = {cv_res2['test_r2'].mean()}\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "8cb5c351",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-20T20:03:54.925817Z",
     "start_time": "2021-09-20T20:03:54.007607Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-137.30460221, -160.94153745, -120.72109177, -130.69395345,\n",
       "       -135.39903531])"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# для тех, кто хочет хочет дополнительно подумать\n",
    "\n",
    "# кросс-валидацию можно проводить на основе своей кастомной метрики, но для этого\n",
    "# из нее нужно сделать объект scorer\n",
    "\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "max_error_scorer = make_scorer(max_error, greater_is_better=False)\n",
    "\n",
    "cv_res3 = cross_validate(lr_mse,\n",
    "                     X,\n",
    "                     y,\n",
    "                     scoring=max_error_scorer,\n",
    "                     cv=num_splits\n",
    "                    )\n",
    "cv_res3['test_score']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a85e17c6",
   "metadata": {},
   "source": [
    "# Немного feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "192c235d",
   "metadata": {},
   "source": [
    "Один из самых главных источников улучшения качества прогноза модели - это информативный набор признаков. Поэтому в попытке улучшить качество нашей модели обогатим наше признаковое пространство попарныи произведениями признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "3f268b47",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-20T20:03:54.996285Z",
     "start_time": "2021-09-20T20:03:54.927938Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['age', 'sex', 'bmi', 'bp', 's1', 's2', 's3', 's4', 's5', 's6'], dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>bp</th>\n",
       "      <th>s1</th>\n",
       "      <th>s2</th>\n",
       "      <th>s3</th>\n",
       "      <th>s4</th>\n",
       "      <th>s5</th>\n",
       "      <th>s6</th>\n",
       "      <th>...</th>\n",
       "      <th>s6_x_age</th>\n",
       "      <th>s6_x_sex</th>\n",
       "      <th>s6_x_bmi</th>\n",
       "      <th>s6_x_bp</th>\n",
       "      <th>s6_x_s1</th>\n",
       "      <th>s6_x_s2</th>\n",
       "      <th>s6_x_s3</th>\n",
       "      <th>s6_x_s4</th>\n",
       "      <th>s6_x_s5</th>\n",
       "      <th>s6_x_s6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.038076</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.061696</td>\n",
       "      <td>0.021872</td>\n",
       "      <td>-0.044223</td>\n",
       "      <td>-0.034821</td>\n",
       "      <td>-0.043401</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>0.019908</td>\n",
       "      <td>-0.017646</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000672</td>\n",
       "      <td>-0.000894</td>\n",
       "      <td>-0.001089</td>\n",
       "      <td>-0.000386</td>\n",
       "      <td>0.000780</td>\n",
       "      <td>0.000614</td>\n",
       "      <td>0.000766</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>-0.000351</td>\n",
       "      <td>0.000311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.001882</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.051474</td>\n",
       "      <td>-0.026328</td>\n",
       "      <td>-0.008449</td>\n",
       "      <td>-0.019163</td>\n",
       "      <td>0.074412</td>\n",
       "      <td>-0.039493</td>\n",
       "      <td>-0.068330</td>\n",
       "      <td>-0.092204</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000174</td>\n",
       "      <td>0.004116</td>\n",
       "      <td>0.004746</td>\n",
       "      <td>0.002428</td>\n",
       "      <td>0.000779</td>\n",
       "      <td>0.001767</td>\n",
       "      <td>-0.006861</td>\n",
       "      <td>0.003641</td>\n",
       "      <td>0.006300</td>\n",
       "      <td>0.008502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.085299</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.044451</td>\n",
       "      <td>-0.005671</td>\n",
       "      <td>-0.045599</td>\n",
       "      <td>-0.034194</td>\n",
       "      <td>-0.032356</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>0.002864</td>\n",
       "      <td>-0.025930</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002212</td>\n",
       "      <td>-0.001314</td>\n",
       "      <td>-0.001153</td>\n",
       "      <td>0.000147</td>\n",
       "      <td>0.001182</td>\n",
       "      <td>0.000887</td>\n",
       "      <td>0.000839</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>-0.000074</td>\n",
       "      <td>0.000672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.089063</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.011595</td>\n",
       "      <td>-0.036656</td>\n",
       "      <td>0.012191</td>\n",
       "      <td>0.024991</td>\n",
       "      <td>-0.036038</td>\n",
       "      <td>0.034309</td>\n",
       "      <td>0.022692</td>\n",
       "      <td>-0.009362</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000834</td>\n",
       "      <td>0.000418</td>\n",
       "      <td>0.000109</td>\n",
       "      <td>0.000343</td>\n",
       "      <td>-0.000114</td>\n",
       "      <td>-0.000234</td>\n",
       "      <td>0.000337</td>\n",
       "      <td>-0.000321</td>\n",
       "      <td>-0.000212</td>\n",
       "      <td>0.000088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.005383</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.036385</td>\n",
       "      <td>0.021872</td>\n",
       "      <td>0.003935</td>\n",
       "      <td>0.015596</td>\n",
       "      <td>0.008142</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>-0.031991</td>\n",
       "      <td>-0.046641</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000251</td>\n",
       "      <td>0.002082</td>\n",
       "      <td>0.001697</td>\n",
       "      <td>-0.001020</td>\n",
       "      <td>-0.000184</td>\n",
       "      <td>-0.000727</td>\n",
       "      <td>-0.000380</td>\n",
       "      <td>0.000121</td>\n",
       "      <td>0.001492</td>\n",
       "      <td>0.002175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>0.041708</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.019662</td>\n",
       "      <td>0.059744</td>\n",
       "      <td>-0.005697</td>\n",
       "      <td>-0.002566</td>\n",
       "      <td>-0.028674</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>0.031193</td>\n",
       "      <td>0.007207</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000301</td>\n",
       "      <td>0.000365</td>\n",
       "      <td>0.000142</td>\n",
       "      <td>0.000431</td>\n",
       "      <td>-0.000041</td>\n",
       "      <td>-0.000018</td>\n",
       "      <td>-0.000207</td>\n",
       "      <td>-0.000019</td>\n",
       "      <td>0.000225</td>\n",
       "      <td>0.000052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>-0.005515</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>-0.015906</td>\n",
       "      <td>-0.067642</td>\n",
       "      <td>0.049341</td>\n",
       "      <td>0.079165</td>\n",
       "      <td>-0.028674</td>\n",
       "      <td>0.034309</td>\n",
       "      <td>-0.018118</td>\n",
       "      <td>0.044485</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000245</td>\n",
       "      <td>0.002255</td>\n",
       "      <td>-0.000708</td>\n",
       "      <td>-0.003009</td>\n",
       "      <td>0.002195</td>\n",
       "      <td>0.003522</td>\n",
       "      <td>-0.001276</td>\n",
       "      <td>0.001526</td>\n",
       "      <td>-0.000806</td>\n",
       "      <td>0.001979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>0.041708</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>-0.015906</td>\n",
       "      <td>0.017282</td>\n",
       "      <td>-0.037344</td>\n",
       "      <td>-0.013840</td>\n",
       "      <td>-0.024993</td>\n",
       "      <td>-0.011080</td>\n",
       "      <td>-0.046879</td>\n",
       "      <td>0.015491</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000646</td>\n",
       "      <td>0.000785</td>\n",
       "      <td>-0.000246</td>\n",
       "      <td>0.000268</td>\n",
       "      <td>-0.000578</td>\n",
       "      <td>-0.000214</td>\n",
       "      <td>-0.000387</td>\n",
       "      <td>-0.000172</td>\n",
       "      <td>-0.000726</td>\n",
       "      <td>0.000240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>-0.045472</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>0.039062</td>\n",
       "      <td>0.001215</td>\n",
       "      <td>0.016318</td>\n",
       "      <td>0.015283</td>\n",
       "      <td>-0.028674</td>\n",
       "      <td>0.026560</td>\n",
       "      <td>0.044528</td>\n",
       "      <td>-0.025930</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001179</td>\n",
       "      <td>0.001158</td>\n",
       "      <td>-0.001013</td>\n",
       "      <td>-0.000032</td>\n",
       "      <td>-0.000423</td>\n",
       "      <td>-0.000396</td>\n",
       "      <td>0.000744</td>\n",
       "      <td>-0.000689</td>\n",
       "      <td>-0.001155</td>\n",
       "      <td>0.000672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>-0.045472</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.073030</td>\n",
       "      <td>-0.081414</td>\n",
       "      <td>0.083740</td>\n",
       "      <td>0.027809</td>\n",
       "      <td>0.173816</td>\n",
       "      <td>-0.039493</td>\n",
       "      <td>-0.004220</td>\n",
       "      <td>0.003064</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000139</td>\n",
       "      <td>-0.000137</td>\n",
       "      <td>-0.000224</td>\n",
       "      <td>-0.000249</td>\n",
       "      <td>0.000257</td>\n",
       "      <td>0.000085</td>\n",
       "      <td>0.000533</td>\n",
       "      <td>-0.000121</td>\n",
       "      <td>-0.000013</td>\n",
       "      <td>0.000009</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>442 rows × 110 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          age       sex       bmi        bp        s1        s2        s3  \\\n",
       "0    0.038076  0.050680  0.061696  0.021872 -0.044223 -0.034821 -0.043401   \n",
       "1   -0.001882 -0.044642 -0.051474 -0.026328 -0.008449 -0.019163  0.074412   \n",
       "2    0.085299  0.050680  0.044451 -0.005671 -0.045599 -0.034194 -0.032356   \n",
       "3   -0.089063 -0.044642 -0.011595 -0.036656  0.012191  0.024991 -0.036038   \n",
       "4    0.005383 -0.044642 -0.036385  0.021872  0.003935  0.015596  0.008142   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "437  0.041708  0.050680  0.019662  0.059744 -0.005697 -0.002566 -0.028674   \n",
       "438 -0.005515  0.050680 -0.015906 -0.067642  0.049341  0.079165 -0.028674   \n",
       "439  0.041708  0.050680 -0.015906  0.017282 -0.037344 -0.013840 -0.024993   \n",
       "440 -0.045472 -0.044642  0.039062  0.001215  0.016318  0.015283 -0.028674   \n",
       "441 -0.045472 -0.044642 -0.073030 -0.081414  0.083740  0.027809  0.173816   \n",
       "\n",
       "           s4        s5        s6  ...  s6_x_age  s6_x_sex  s6_x_bmi  \\\n",
       "0   -0.002592  0.019908 -0.017646  ... -0.000672 -0.000894 -0.001089   \n",
       "1   -0.039493 -0.068330 -0.092204  ...  0.000174  0.004116  0.004746   \n",
       "2   -0.002592  0.002864 -0.025930  ... -0.002212 -0.001314 -0.001153   \n",
       "3    0.034309  0.022692 -0.009362  ...  0.000834  0.000418  0.000109   \n",
       "4   -0.002592 -0.031991 -0.046641  ... -0.000251  0.002082  0.001697   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "437 -0.002592  0.031193  0.007207  ...  0.000301  0.000365  0.000142   \n",
       "438  0.034309 -0.018118  0.044485  ... -0.000245  0.002255 -0.000708   \n",
       "439 -0.011080 -0.046879  0.015491  ...  0.000646  0.000785 -0.000246   \n",
       "440  0.026560  0.044528 -0.025930  ...  0.001179  0.001158 -0.001013   \n",
       "441 -0.039493 -0.004220  0.003064  ... -0.000139 -0.000137 -0.000224   \n",
       "\n",
       "      s6_x_bp   s6_x_s1   s6_x_s2   s6_x_s3   s6_x_s4   s6_x_s5   s6_x_s6  \n",
       "0   -0.000386  0.000780  0.000614  0.000766  0.000046 -0.000351  0.000311  \n",
       "1    0.002428  0.000779  0.001767 -0.006861  0.003641  0.006300  0.008502  \n",
       "2    0.000147  0.001182  0.000887  0.000839  0.000067 -0.000074  0.000672  \n",
       "3    0.000343 -0.000114 -0.000234  0.000337 -0.000321 -0.000212  0.000088  \n",
       "4   -0.001020 -0.000184 -0.000727 -0.000380  0.000121  0.001492  0.002175  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "437  0.000431 -0.000041 -0.000018 -0.000207 -0.000019  0.000225  0.000052  \n",
       "438 -0.003009  0.002195  0.003522 -0.001276  0.001526 -0.000806  0.001979  \n",
       "439  0.000268 -0.000578 -0.000214 -0.000387 -0.000172 -0.000726  0.000240  \n",
       "440 -0.000032 -0.000423 -0.000396  0.000744 -0.000689 -0.001155  0.000672  \n",
       "441 -0.000249  0.000257  0.000085  0.000533 -0.000121 -0.000013  0.000009  \n",
       "\n",
       "[442 rows x 110 columns]"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import copy\n",
    "\n",
    "cols = copy.deepcopy(X.columns)\n",
    "print(cols)\n",
    "\n",
    "for col1 in cols:\n",
    "    for col2 in cols:\n",
    "        col_name = col1 + '_x_' + col2\n",
    "        if col_name not in X.columns:\n",
    "            X[col_name] = X[col1]*X[col2]\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e5b9d73",
   "metadata": {},
   "source": [
    "# Переобучение и регуляризация"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31079bbe",
   "metadata": {},
   "source": [
    "Переобучение - ситуация, когда модель хорошо выучила обучающую выборку, но при этом показывает гораздо более низкое качество точности на тестовых данных. Это можно интерпретровать как модель стала слишком специфичной и потеряла обобщающую способность\n",
    "\n",
    "В случае линеной регрессии, одним из симптомов переобучения являются высокие значения весов. С этим борются регуляризацией.\n",
    "\n",
    "Регуляризация Lasso или L1-регуляризация:\n",
    "\n",
    "$Q_{lasso}(w) = Q(w) + \\alpha \\Sigma_{j=0}^{k}|w_{k}|$\n",
    "\n",
    "Регуляризация Ridge или L2-регуляризация:\n",
    "\n",
    "$Q_{ridge}(w) = Q(w) + \\alpha \\Sigma_{j=0}^{k}w_{k}^{2}$\n",
    "\n",
    "\n",
    "Как было рассказано в лекции, несмотря на то, что оба вида регуляризации ведут к занижению значений весов, отличие регуляризации Lasso заключается в том, что она может привести часть весов к 0 (что эквивалетно безинформативности  соответствующего признака), в случае Ridge регрессии веса могут быть сколько угодно близки к 0, но никогда не равны.\n",
    "\n",
    "Объяснение в лекции :)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "ba3352a3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-20T20:03:55.004798Z",
     "start_time": "2021-09-20T20:03:54.997613Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "e6636439",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-20T20:03:55.074878Z",
     "start_time": "2021-09-20T20:03:55.006328Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha=1e-08\n",
      "Train MSE: 2390.1762554969896\n",
      "Test MSE: 3949.8711596094763\n",
      "[ 1.27438354e+02 -1.50511732e+01  3.47449296e+02  4.07816016e+02\n",
      " -1.90916688e+02  1.14064153e+02 -4.61015129e+02 -4.11662794e+01\n",
      "  5.25899314e+02  8.36399658e+01  1.62587725e+03  3.33902078e+03\n",
      " -4.12982806e+02  4.32142657e+03 -7.18027380e+03  1.22546847e+03\n",
      "  6.85790174e+03  6.86558325e+03  1.21552657e+03  2.81299904e+02\n",
      " -8.12666230e+02 -5.35698281e+04 -2.04188295e+03  1.78479741e+03\n",
      "  4.95513918e+03 -2.75683896e+03 -1.80870956e+03 -6.72850847e+03\n",
      "  2.95435303e+03  1.44723973e+03 -7.47787315e+02 -8.15908232e+02\n",
      "  7.56743275e+01  2.74076625e+03 -1.22860438e+04  1.02622418e+04\n",
      "  7.24461495e+03 -9.92069930e+02  6.78578871e+03  8.20407298e+02\n",
      " -4.41744169e+02 -8.66161468e+02 -2.96032644e+02  1.03132479e+03\n",
      "  6.72864633e+03 -7.90952769e+03 -4.20371434e+03 -2.05808150e+03\n",
      " -5.48493641e+03 -5.72679460e+02 -5.57377896e+03  6.11008895e+03\n",
      " -1.17464047e+04  1.49279977e+04  2.80081027e+03  1.76778627e+02\n",
      " -1.31697030e+04 -1.66798153e+04 -6.03053780e+03  9.39315921e+03\n",
      "  1.65232412e+02 -3.00910279e+03  1.03978165e+04 -9.08217489e+03\n",
      "  7.40739902e+03 -6.70333475e+03  2.72066308e+03  2.74598459e+03\n",
      "  7.23780822e+03 -7.45838598e+03  5.09986657e+03 -5.12216731e+03\n",
      "  3.97979433e+03 -7.01123084e+03 -1.21598763e+04  1.18633361e+04\n",
      "  1.19509365e+04  1.57592603e+04  7.87960124e+03 -2.63009145e+03\n",
      "  4.68278056e+03 -2.07127092e+03  2.82099652e+03  7.99940819e+02\n",
      " -1.57591403e+03  3.72955172e+03 -1.09314620e+03  1.21896610e+04\n",
      " -1.23364532e+04  2.59588661e+03  1.75875382e+03 -2.81846193e+03\n",
      "  3.72230085e+03 -4.00484271e+03 -1.14219400e+04  1.03127477e+04\n",
      "  8.78511386e+02  1.97972360e+03  1.04163828e+04 -5.64199846e+03\n",
      "  6.77752733e+02 -5.88863314e+01 -8.57562026e+02 -1.54172803e+03\n",
      "  4.31559013e+02 -2.15772497e+03  2.34389277e+03  3.61568993e+03\n",
      "  2.55805693e+02  1.31273489e+03] \n",
      "\n",
      "alpha=0.25\n",
      "Train MSE: 3113.5974768514457\n",
      "Test MSE: 2769.347676886417\n",
      "[   0.          -68.39479953  450.14124927  260.51679408   -0.\n",
      "   -0.         -213.68383353    0.          399.95636389    4.79068623\n",
      "    0.            0.            0.            0.           -0.\n",
      "   -0.           -0.            0.            0.            0.\n",
      "    0.           -0.            0.            0.            0.\n",
      "   -0.            0.           -0.            0.            0.\n",
      "    0.            0.            0.            0.            0.\n",
      "    0.           -0.            0.            0.            0.\n",
      "    0.            0.            0.            0.            0.\n",
      "    0.           -0.            0.            0.            0.\n",
      "   -0.            0.            0.            0.            0.\n",
      "    0.            0.            0.            0.            0.\n",
      "   -0.           -0.            0.            0.            0.\n",
      "    0.           -0.            0.            0.            0.\n",
      "   -0.            0.           -0.           -0.            0.\n",
      "   -0.            0.           -0.            0.           -0.\n",
      "    0.           -0.            0.            0.            0.\n",
      "    0.           -0.            0.           -0.            0.\n",
      "    0.            0.            0.            0.            0.\n",
      "    0.            0.           -0.            0.            0.\n",
      "    0.            0.            0.            0.            0.\n",
      "    0.           -0.            0.            0.            0.        ] \n",
      "\n",
      "alpha=0.5\n",
      "Train MSE: 3347.778653665246\n",
      "Test MSE: 2968.618590706407\n",
      "[   0.           -0.          414.63690192  171.21656434    0.\n",
      "    0.         -112.21083517    0.          365.56752829    0.\n",
      "    0.            0.            0.            0.           -0.\n",
      "   -0.           -0.            0.            0.            0.\n",
      "    0.           -0.            0.            0.            0.\n",
      "   -0.            0.           -0.            0.            0.\n",
      "    0.            0.            0.            0.            0.\n",
      "   -0.           -0.            0.            0.            0.\n",
      "    0.            0.            0.            0.            0.\n",
      "    0.           -0.            0.            0.            0.\n",
      "   -0.            0.            0.            0.            0.\n",
      "    0.           -0.            0.            0.            0.\n",
      "   -0.           -0.           -0.            0.            0.\n",
      "    0.            0.            0.           -0.            0.\n",
      "   -0.            0.           -0.           -0.           -0.\n",
      "    0.           -0.           -0.            0.           -0.\n",
      "    0.           -0.            0.            0.            0.\n",
      "    0.           -0.            0.            0.            0.\n",
      "    0.            0.            0.            0.            0.\n",
      "   -0.            0.            0.            0.            0.\n",
      "    0.            0.            0.            0.            0.\n",
      "    0.           -0.            0.            0.            0.        ] \n",
      "\n",
      "alpha=0.75\n",
      "Train MSE: 3641.775718886956\n",
      "Test MSE: 3309.1558360749414\n",
      "[  0.          -0.         364.71836457  97.19972818   0.\n",
      "   0.         -40.24371021   0.         326.27521152   0.\n",
      "   0.           0.           0.           0.          -0.\n",
      "  -0.          -0.           0.           0.           0.\n",
      "   0.          -0.           0.           0.           0.\n",
      "  -0.           0.          -0.           0.           0.\n",
      "   0.           0.           0.           0.          -0.\n",
      "  -0.          -0.           0.           0.           0.\n",
      "   0.           0.           0.           0.           0.\n",
      "   0.          -0.           0.           0.           0.\n",
      "  -0.           0.          -0.           0.           0.\n",
      "   0.          -0.           0.           0.           0.\n",
      "  -0.          -0.          -0.           0.           0.\n",
      "   0.           0.           0.          -0.           0.\n",
      "  -0.           0.          -0.          -0.          -0.\n",
      "   0.          -0.          -0.           0.          -0.\n",
      "   0.          -0.           0.           0.           0.\n",
      "   0.          -0.           0.           0.           0.\n",
      "   0.           0.           0.           0.           0.\n",
      "  -0.           0.           0.           0.           0.\n",
      "   0.           0.           0.           0.           0.\n",
      "   0.          -0.           0.           0.           0.        ] \n",
      "\n",
      "alpha=1.0\n",
      "Train MSE: 4023.4876772899343\n",
      "Test MSE: 3803.7716939970855\n",
      "[  0.          -0.         306.53762103  26.16368696   0.\n",
      "   0.          -0.           0.         276.35183321   0.\n",
      "   0.           0.          -0.           0.          -0.\n",
      "  -0.          -0.           0.           0.           0.\n",
      "   0.          -0.          -0.           0.           0.\n",
      "  -0.           0.          -0.           0.           0.\n",
      "  -0.          -0.           0.           0.          -0.\n",
      "  -0.           0.           0.           0.           0.\n",
      "   0.           0.           0.           0.           0.\n",
      "   0.          -0.           0.           0.           0.\n",
      "  -0.           0.          -0.           0.           0.\n",
      "   0.          -0.           0.           0.           0.\n",
      "  -0.          -0.          -0.           0.           0.\n",
      "   0.           0.           0.          -0.           0.\n",
      "  -0.           0.           0.          -0.          -0.\n",
      "   0.          -0.          -0.           0.          -0.\n",
      "   0.          -0.           0.           0.           0.\n",
      "   0.          -0.           0.           0.           0.\n",
      "   0.           0.           0.           0.           0.\n",
      "  -0.           0.           0.           0.           0.\n",
      "   0.           0.           0.           0.           0.\n",
      "   0.          -0.           0.           0.           0.        ] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# альфа - это гиперпараметр, посмотрим как зависят значения весов от него\n",
    "\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "for a in np.arange(0, 1.1, 0.25):\n",
    "    if a == 0:\n",
    "        a += 0.00000001\n",
    "    lasso = Lasso(alpha=a)\n",
    "    lasso.fit(X_train, y_train)\n",
    "\n",
    "    y_pred_tr = lasso.predict(X_train)\n",
    "    y_pred2 = lasso.predict(X_test)\n",
    "\n",
    "    print('alpha={}'.format(a))\n",
    "    print('Train MSE:', mean_squared_error(y_train, y_pred_tr))\n",
    "    print('Test MSE:', mean_squared_error(y_test, y_pred2))\n",
    "    print(lasso.coef_,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "c171dd89",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-20T20:03:55.133640Z",
     "start_time": "2021-09-20T20:03:55.076921Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha=1e-08\n",
      "Train MSE: 2377.754627755604\n",
      "Test MSE: 3967.0196054589355\n",
      "[ 1.33821633e+02 -3.45580133e+02  3.58153984e+02  3.99796660e+02\n",
      " -8.13477452e+03  7.13407402e+03  2.48632211e+03 -1.06877319e+02\n",
      "  3.16360015e+03  9.24768150e+01  1.55766195e+03  1.18075590e+03\n",
      " -6.86593693e+02  1.92094930e+03 -5.46898232e+03  4.66430557e-01\n",
      "  5.48838105e+03  5.59180275e+03  1.33179238e+03  5.31627231e+02\n",
      "  1.18075590e+03 -2.08677817e+00 -1.49926150e+03  4.14963339e+02\n",
      "  7.45222519e+03 -4.34441172e+03 -4.56509321e+03 -4.90948783e+03\n",
      " -4.14044135e+02  6.97501950e+02 -6.86593693e+02 -1.49926150e+03\n",
      " -4.62534082e+01  1.30089609e+03 -9.22149306e+03  7.89431718e+03\n",
      "  4.66591370e+03  1.10544712e+03  4.53686181e+03 -8.88217450e+01\n",
      "  1.92094930e+03  4.14963339e+02  1.30089609e+03  1.01576650e+03\n",
      "  9.06628608e+03 -6.95411312e+03 -5.00413878e+03 -6.88775241e+02\n",
      " -4.07085582e+03 -1.02652932e+03 -5.46898232e+03  7.45222519e+03\n",
      " -9.22149306e+03  9.06628607e+03  9.21090997e+04 -6.29456897e+04\n",
      " -5.56687857e+04 -2.62306556e+04 -3.11458827e+04  7.60845133e+03\n",
      "  4.66434419e-01 -4.34441172e+03  7.89431718e+03 -6.95411312e+03\n",
      " -6.29456897e+04  4.22635504e+04  4.02535353e+04  1.73356082e+04\n",
      "  2.40442234e+04 -7.28370161e+03  5.48838105e+03 -4.56509321e+03\n",
      "  4.66591370e+03 -5.00413879e+03 -5.56687857e+04  4.02535353e+04\n",
      "  3.15851530e+04  1.44531783e+04  1.62231700e+04 -1.13655712e+03\n",
      "  5.59180275e+03 -4.90948783e+03  1.10544713e+03 -6.88775239e+02\n",
      " -2.62306556e+04  1.73356082e+04  1.44531783e+04  1.37560053e+04\n",
      "  1.25914558e+03  3.31464481e+03  1.33179238e+03 -4.14044135e+02\n",
      "  4.53686181e+03 -4.07085582e+03 -3.11458827e+04  2.40442234e+04\n",
      "  1.62231700e+04  1.25914558e+03  2.83081840e+04 -3.81344649e+03\n",
      "  5.31627229e+02  6.97501950e+02 -8.88217436e+01 -1.02652932e+03\n",
      "  7.60845133e+03 -7.28370161e+03 -1.13655712e+03  3.31464481e+03\n",
      " -3.81344649e+03  1.44491142e+03] \n",
      "\n",
      "alpha=0.25\n",
      "Train MSE: 3023.145824819325\n",
      "Test MSE: 2851.4339632244405\n",
      "[  41.69406069 -176.17174156  377.43713504  286.66872662  -40.1488306\n",
      "  -61.43788641 -223.20720028  132.07626105  330.17655884  113.34229448\n",
      "   23.18049304   26.14526602    3.29287534   24.51319542   -7.23001341\n",
      "   -9.62133143   -7.18743625    7.86508262   11.52597656   14.7959913\n",
      "   26.14526602   -1.06380993    3.29066185   12.97873312    5.4735109\n",
      "   -0.60858797    6.42447465   -2.25341855    7.32622872   12.12513129\n",
      "    3.29287534    3.29066185   25.57060795   19.39073853    4.74964059\n",
      "    5.04096405   -4.51155367    8.23168803    8.75418896   12.64381177\n",
      "   24.51319542   12.97873312   19.39073853   18.18251381    6.57297774\n",
      "    6.97151569   -3.8904519     4.47796701    7.88015058   10.39967065\n",
      "   -7.23001341    5.4735109     4.74964059    6.57297774   12.57187497\n",
      "    9.97077425    4.54453833    2.10233156    4.15757871   11.15448001\n",
      "   -9.62133143   -0.60858797    5.04096405    6.97151569    9.97077425\n",
      "    7.47374614   -0.82881186    7.01983119    4.64450598   11.27740353\n",
      "   -7.18743625    6.42447465   -4.51155367   -3.8904519     4.54453833\n",
      "   -0.82881186    3.27803615   -2.37269142    8.42453739   -4.00423443\n",
      "    7.86508262   -2.25341855    8.23168803    4.47796701    2.10233156\n",
      "    7.01983119   -2.37269142    7.8159931    -6.143072     13.53951304\n",
      "   11.52597656    7.32622872    8.75418896    7.88015058    4.15757871\n",
      "    4.64450598    8.42453739   -6.143072     -2.17235832    7.6825591\n",
      "   14.7959913    12.12513129   12.64381177   10.39967065   11.15448001\n",
      "   11.27740353   -4.00423443   13.53951304    7.6825591    21.16883945] \n",
      "\n",
      "alpha=0.5\n",
      "Train MSE: 3170.473352640688\n",
      "Test MSE: 3026.5742802339805\n",
      "[  45.03217558 -126.5328504   319.81678176  239.50955566  -14.90339458\n",
      "  -41.2400278  -193.33916408  129.56791297  277.97762502  116.29367882\n",
      "   11.00921343   12.84211013    1.38495077   12.97050873   -4.73276365\n",
      "   -6.34038019   -4.06642259    3.58665168    6.23784557    7.70714341\n",
      "   12.84211013   -0.76406637    1.03276747    6.39558791    2.55631026\n",
      "   -0.64814421    3.82831589   -1.0745072     3.30809335    5.72438107\n",
      "    1.38495077    1.03276747   16.79991563   10.48915057    1.65767898\n",
      "    1.23651319   -2.63621288    4.37960577    5.51619278    7.08744745\n",
      "   12.97050873    6.39558791   10.48915057   11.11130034    3.41455387\n",
      "    2.75964048   -1.54832333    2.07027732    4.84657942    5.5704866\n",
      "   -4.73276365    2.55631026    1.65767898    3.41455387    6.0611003\n",
      "    4.3287498     1.90629487    1.5754745     2.39816937    5.64988125\n",
      "   -6.34038019   -0.64814421    1.23651319    2.75964048    4.3287498\n",
      "    3.11118582    0.78723962    2.83131689    0.88179883    5.07499025\n",
      "   -4.06642259    3.82831589   -2.63621288   -1.54832333    1.90629487\n",
      "    0.78723962   -0.53815411   -0.94274798    3.4432049    -2.23604364\n",
      "    3.58665168   -1.0745072     4.37960577    2.07027732    1.5754745\n",
      "    2.83131689   -0.94274798    5.42702537   -1.75993283    7.51514356\n",
      "    6.23784557    3.30809335    5.51619278    4.84657942    2.39816937\n",
      "    0.88179883    3.4432049    -1.75993283    1.40293647    4.67595617\n",
      "    7.70714341    5.72438107    7.08744745    5.5704866     5.64988125\n",
      "    5.07499025   -2.23604364    7.51514356    4.67595617   10.78053625] \n",
      "\n",
      "alpha=0.75\n",
      "Train MSE: 3312.3791706949637\n",
      "Test MSE: 3198.0284079017524\n",
      "[ 4.59997366e+01 -9.60448386e+01  2.78545363e+02  2.07950776e+02\n",
      " -1.54533627e+00 -2.56036433e+01 -1.72142102e+02  1.23757687e+02\n",
      "  2.43249479e+02  1.13184847e+02  6.95405401e+00  8.39384774e+00\n",
      "  6.69360407e-01  8.87409391e+00 -3.78370393e+00 -5.03555146e+00\n",
      " -2.92293364e+00  2.15733640e+00  4.28863849e+00  5.18625504e+00\n",
      "  8.39384774e+00 -5.79965052e-01  3.46883494e-01  4.18618868e+00\n",
      "  1.60120117e+00 -6.05126782e-01  2.85831042e+00 -7.01609846e-01\n",
      "  2.00309203e+00  3.58830364e+00  6.69360407e-01  3.46883494e-01\n",
      "  1.30228150e+01  7.25650729e+00  7.08015376e-01  1.40741946e-01\n",
      " -1.90096984e+00  3.01864671e+00  4.18438631e+00  5.00599320e+00\n",
      "  8.87409391e+00  4.18618868e+00  7.25650729e+00  8.29379890e+00\n",
      "  2.25352707e+00  1.40857088e+00 -8.33139261e-01  1.26474520e+00\n",
      "  3.60009029e+00  3.77592275e+00 -3.78370393e+00  1.60120117e+00\n",
      "  7.08015376e-01  2.25352707e+00  3.93605853e+00  2.57595364e+00\n",
      "  1.08800980e+00  1.30497737e+00  1.74041128e+00  3.73615064e+00\n",
      " -5.03555146e+00 -6.05126782e-01  1.40741946e-01  1.40857088e+00\n",
      "  2.57595364e+00  1.79281146e+00  1.12024173e+00  1.56215230e+00\n",
      " -1.38072122e-01  3.04266158e+00 -2.92293364e+00  2.85831042e+00\n",
      " -1.90096984e+00 -8.33139261e-01  1.08800980e+00  1.12024173e+00\n",
      " -1.44759356e+00 -5.63470279e-01  1.91477991e+00 -1.57067719e+00\n",
      "  2.15733640e+00 -7.01609846e-01  3.01864671e+00  1.26474520e+00\n",
      "  1.30497737e+00  1.56215230e+00 -5.63470279e-01  4.45894096e+00\n",
      " -5.10792925e-01  5.31203599e+00  4.28863849e+00  2.00309203e+00\n",
      "  4.18438631e+00  3.60009029e+00  1.74041128e+00 -1.38072122e-01\n",
      "  1.91477991e+00 -5.10792925e-01  2.13706355e+00  3.46397876e+00\n",
      "  5.18625504e+00  3.58830364e+00  5.00599320e+00  3.77592275e+00\n",
      "  3.73615064e+00  3.04266158e+00 -1.57067719e+00  5.31203599e+00\n",
      "  3.46397876e+00  7.18332724e+00] \n",
      "\n",
      "alpha=1.0\n",
      "Train MSE: 3442.5593169700687\n",
      "Test MSE: 3357.02431926293\n",
      "[ 4.56953079e+01 -7.57045222e+01  2.47418454e+02  1.84832274e+02\n",
      "  6.65341640e+00 -1.46397418e+01 -1.55826171e+02  1.17593837e+02\n",
      "  2.17566979e+02  1.08318338e+02  4.95887772e+00  6.18397581e+00\n",
      "  3.07914568e-01  6.74451804e+00 -3.23061797e+00 -4.26447359e+00\n",
      " -2.31267781e+00  1.46224218e+00  3.25500249e+00  3.88237456e+00\n",
      "  6.18397581e+00 -4.57140412e-01  5.49975031e-02  3.09034484e+00\n",
      "  1.14525004e+00 -5.47509505e-01  2.32363826e+00 -5.15661521e-01\n",
      "  1.37964678e+00  2.54212021e+00  3.07914568e-01  5.49975031e-02\n",
      "  1.07668868e+01  5.55325094e+00  2.90169883e-01 -3.07657604e-01\n",
      " -1.48728679e+00  2.31289363e+00  3.41547419e+00  3.89002702e+00\n",
      "  6.74451804e+00  3.09034484e+00  5.55325094e+00  6.70401129e+00\n",
      "  1.65177400e+00  7.85195444e-01 -5.12495226e-01  8.78079606e-01\n",
      "  2.89165759e+00  2.83038515e+00 -3.23061797e+00  1.14525004e+00\n",
      "  2.90169883e-01  1.65177400e+00  2.91863178e+00  1.78137457e+00\n",
      "  7.03636620e-01  1.14240638e+00  1.39520039e+00  2.76733246e+00\n",
      " -4.26447359e+00 -5.47509505e-01 -3.07657604e-01  7.85195444e-01\n",
      "  1.78137457e+00  1.21486997e+00  1.18780048e+00  1.00115304e+00\n",
      " -5.20999643e-01  2.06814725e+00 -2.31267781e+00  2.32363826e+00\n",
      " -1.48728679e+00 -5.12495226e-01  7.03636620e-01  1.18780048e+00\n",
      " -1.74216495e+00 -4.04755520e-01  1.21785239e+00 -1.21576247e+00\n",
      "  1.46224218e+00 -5.15661521e-01  2.31289363e+00  8.78079606e-01\n",
      "  1.14240638e+00  1.00115304e+00 -4.04755520e-01  3.88503263e+00\n",
      "  1.49830016e-02  4.14484523e+00  3.25500249e+00  1.37964678e+00\n",
      "  3.41547419e+00  2.89165759e+00  1.39520039e+00 -5.20999643e-01\n",
      "  1.21785239e+00  1.49830016e-02  2.29316945e+00  2.78034546e+00\n",
      "  3.88237456e+00  2.54212021e+00  3.89002702e+00  2.83038515e+00\n",
      "  2.76733246e+00  2.06814725e+00 -1.21576247e+00  4.14484523e+00\n",
      "  2.78034546e+00  5.36195453e+00] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# альфа - это гиперпараметр, посмотрим как зависят значения весов от него\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "for a in np.arange(0, 1.1, 0.25):\n",
    "    if a == 0:\n",
    "        a += 0.00000001\n",
    "    ridge = Ridge(alpha=a)\n",
    "    ridge.fit(X_train, y_train)\n",
    "\n",
    "    y_pred_tr = ridge.predict(X_train)\n",
    "    y_pred2 = ridge.predict(X_test)\n",
    "\n",
    "    print('alpha={}'.format(a))\n",
    "    print('Train MSE:', mean_squared_error(y_train, y_pred_tr))\n",
    "    print('Test MSE:', mean_squared_error(y_test, y_pred2))\n",
    "    print(ridge.coef_,'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02fb320a",
   "metadata": {},
   "source": [
    "А какой коэффициент альфа лучший ? И нужна ли здесь регуляризация ?\n",
    "\n",
    "Чтобы ответить на этот вопрос мы можем с помощью кросс-валидации перебрать различные значения альфы и выбрать лучшее значение. Этот процесс называется оптимизацией гиперпараметров. Альфа является гиперпараметром, потому что задача оптимизации функционала не позволяет найти ее оптимальное значение (в отличие от весов регрессии)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "a04ffd86",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-20T20:03:55.295117Z",
     "start_time": "2021-09-20T20:03:55.135370Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal alpha value is 0.025125628240201005\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LassoCV\n",
    "\n",
    "n_alphas = 200\n",
    "alphas = np.linspace(1e-10, 5, n_alphas)\n",
    "\n",
    "lasso_cv = LassoCV(alphas=alphas, cv=5, random_state=42)\n",
    "lasso_cv.fit(X, y)\n",
    "\n",
    "print(f'Optimal alpha value is {lasso_cv.alpha_}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "20de9b2c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-20T20:04:01.101956Z",
     "start_time": "2021-09-20T20:03:55.296894Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 0.025125628240201005}\n"
     ]
    }
   ],
   "source": [
    "# Более общий способ использования кросс-валидации для поиска лучшего набора гиперпараметров\n",
    "\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params = {'alpha':alphas}\n",
    "#print(params)\n",
    "cv = GridSearchCV(lasso,\n",
    "                  params,\n",
    "                  scoring='r2',\n",
    "                  cv=num_splits\n",
    "                 )\n",
    "cv.fit(X, y)\n",
    "\n",
    "print(cv.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b10f2a2",
   "metadata": {},
   "source": [
    "Больше про то, как задавать поле поиска и какие еще есть методы оптимизации гиперпараметров можете прочитать здесь\n",
    "\n",
    "https://scikit-learn.org/stable/modules/grid_search.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
